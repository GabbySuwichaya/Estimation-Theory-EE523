## Tutorial 2: Probabilistic Convergence Visualization

by *Suwichaya Suwanwimolkul, Ph.D.*

The coding exercies and examples are used as parts of  *Lecture II: Probabilistic Convergence* in **Estimation Theory EE2102523**. 
The lecture handout for [`Lecture II: Probabilistic Convergence` ](LectureII.pdf) and [Homework](HW2.pdf) are attached in this folder.


The topics covered in this exercise are: 
- [Convergence in Distribution](#convergences-in-distribution)
    - [Simulation of Central Limit Theorem](#simulation-of-central-limit-theorem-bernoulli--uniform)
    - [KL Divergence](#kl-divergence)
- [Convergence in Probability](#convergence-in-probability)
    - [Simulation of Lecture II Example](#simulation-of-example---noise-in-lecture-2)
- [Almost Sure Convergence](#almost-surely-converge)
    - [Converge almost completely](#converges-almost-completely)
    - [Simulation of HW 2.1.3](#simulation-for-the-3rd-question-of-example-16) 


### Quick start 

You can also try everything on your local machine by ...


Install dependenies listed in `requirements.txt` by 

```
pip install -r requirements.txt
```

Then, start the jupyternote book [`main.ipynb`](main.ipynb).
 

 
### Final Notes.
-  Don't forget to install the dependency `pip install -r requirements.txt`
- `utils.py` contains the supplenmary implementations for each fucntion used in `main.ipynb` 
- Good luck! 